# 운영용 PC 배포 스크립트

## 사전 준비사항

### 1. 운영용 PC 요구사항
- **OS**: Ubuntu 20.04+ 또는 CentOS 8+
- **CPU**: 8코어 이상
- **RAM**: 32GB 이상
- **Storage**: 500GB 이상 SSD
- **Network**: 고정 IP, 도메인 연결 가능

### 2. 필요한 소프트웨어
- Docker Desktop 20.10+
- Kubernetes 1.24+
- kubectl 1.24+
- Git

## 배포 스크립트

### 1단계: Kubernetes 클러스터 구축

```bash
#!/bin/bash
# production-deploy.sh

echo "🚀 운영용 PC 배포 시작..."

# Kubernetes 클러스터 초기화
echo "📦 Kubernetes 클러스터 초기화 중..."
sudo kubeadm init --pod-network-cidr=10.244.0.0/16

# kubeconfig 설정
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

# 네트워크 플러그인 설치 (Calico)
echo "🌐 네트워크 플러그인 설치 중..."
kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.24.1/manifests/calico.yaml

# MetalLB 설치
echo "🔗 MetalLB 설치 중..."
kubectl apply -f https://raw.githubusercontent.com/metallb/metallb/v0.13.12/config/manifests/metallb-native.yaml

# IPAddressPool 설정
cat <<EOF | kubectl apply -f -
apiVersion: metallb.io/v1beta1
kind: IPAddressPool
metadata:
  name: production-pool
  namespace: metallb-system
spec:
  addresses:
  - 192.168.1.100-192.168.1.110  # 운영용 IP 대역
---
apiVersion: metallb.io/v1beta1
kind: L2Advertisement
metadata:
  name: production-l2
  namespace: metallb-system
spec:
  ipAddressPools:
  - production-pool
EOF

echo "✅ Kubernetes 클러스터 구축 완료!"
```

### 2단계: ArgoCD 설치 및 설정

```bash
#!/bin/bash
# argocd-setup.sh

echo "🔄 ArgoCD 설치 및 설정 중..."

# ArgoCD 설치
echo "📦 ArgoCD 설치 중..."
kubectl create namespace argocd
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml

# ArgoCD 서비스 타입 변경 (LoadBalancer)
kubectl patch svc argocd-server -n argocd -p '{"spec": {"type": "LoadBalancer"}}'

# ArgoCD 준비 대기
echo "⏳ ArgoCD 준비 대기 중..."
kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=argocd-server -n argocd --timeout=300s

# ArgoCD Application 생성 (GitOps 레포지토리 연결)
echo "🔗 ArgoCD Application 생성 중..."
kubectl apply -f https://raw.githubusercontent.com/KORgosu/trip-currency-local-gitops/main/argocd/applications/trip-service-prod.yaml

# ArgoCD 초기 패스워드 확인
echo "🔑 ArgoCD 초기 패스워드:"
kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d
echo ""

echo "✅ ArgoCD 설정 완료!"
echo "🌐 ArgoCD UI 접속: http://<LoadBalancer-IP>:80"
```

### 3단계: 모니터링 스택 설치

```bash
#!/bin/bash
# monitoring-setup.sh

echo "📊 모니터링 스택 설치 중..."

# Prometheus + Grafana 설치
echo "📈 Prometheus + Grafana 설치 중..."
kubectl apply -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/main/bundle.yaml

# ELK Stack 설치
echo "📝 ELK Stack 설치 중..."
kubectl apply -f https://raw.githubusercontent.com/elastic/cloud-on-k8s/main/config/recipes/elasticsearch/elasticsearch.yaml
kubectl apply -f https://raw.githubusercontent.com/elastic/cloud-on-k8s/main/config/recipes/kibana/kibana.yaml

# 모니터링 스택 준비 대기
echo "⏳ 모니터링 스택 준비 대기 중..."
kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=prometheus-operator -n default --timeout=300s
kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=elasticsearch -n default --timeout=300s

echo "✅ 모니터링 스택 설치 완료!"
```

### 4단계: 전체 배포 실행

```bash
#!/bin/bash
# full-deployment.sh

echo "🚀 전체 배포 시작..."

# 1단계: Kubernetes 클러스터 구축
./production-deploy.sh

# 2단계: ArgoCD 설치 및 설정
./argocd-setup.sh

# 3단계: 모니터링 스택 설치
./monitoring-setup.sh

# 4단계: 배포 상태 확인
echo "🔍 배포 상태 확인 중..."
kubectl get all -A
kubectl get applications -n argocd

echo "✅ 전체 배포 완료!"
echo "🌐 접속 URL:"
echo "   - ArgoCD: http://<LoadBalancer-IP>:80"
echo "   - Grafana: http://<LoadBalancer-IP>:3000"
echo "   - Kibana: http://<LoadBalancer-IP>:5601"
```

## 배포 후 확인사항

### 1. 서비스 상태 확인
```bash
# 전체 리소스 상태 확인
kubectl get all -A

# ArgoCD Application 상태 확인
kubectl get applications -n argocd

# Trip Service 파드 상태 확인
kubectl get pods -n trip-service-prod
```

### 2. 로그 확인
```bash
# Trip Service 로그 확인
kubectl logs -l app=service-frontend -n trip-service-prod
kubectl logs -l app=service-currency -n trip-service-prod
kubectl logs -l app=service-history -n trip-service-prod
kubectl logs -l app=service-ranking -n trip-service-prod
```

### 3. 모니터링 확인
```bash
# Prometheus 메트릭 확인
kubectl port-forward svc/prometheus-operated 9090:9090

# Grafana 대시보드 확인
kubectl port-forward svc/grafana 3000:3000

# Kibana 로그 확인
kubectl port-forward svc/kibana 5601:5601
```

## 자동 배포 테스트

### 1. 개발 PC에서 코드 변경
```bash
# 소스 코드 변경 후 푸시
git add .
git commit -m "Test production deployment"
git push origin main
```

### 2. 운영용 PC에서 자동 배포 확인
```bash
# ArgoCD에서 변경사항 감지 확인
kubectl get applications -n argocd

# 새로운 파드 배포 확인
kubectl get pods -n trip-service-prod
```

## 트러블슈팅

### 1. 일반적인 문제들
- **네트워크 연결 문제**: 방화벽 설정 확인
- **리소스 부족**: 노드 리소스 확인
- **이미지 Pull 실패**: Docker Registry 인증 확인

### 2. 로그 확인
```bash
# ArgoCD 로그
kubectl logs -n argocd deployment/argocd-application-controller

# Trip Service 로그
kubectl logs -n trip-service-prod deployment/service-frontend
```

### 3. 상태 확인
```bash
# 이벤트 확인
kubectl get events -n trip-service-prod --sort-by='.lastTimestamp'

# 리소스 사용량 확인
kubectl top pods -n trip-service-prod
```

## 보안 설정

### 1. TLS 인증서 설정
```bash
# cert-manager 설치
kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.0/cert-manager.yaml

# Let's Encrypt ClusterIssuer 생성
kubectl apply -f - <<EOF
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: letsencrypt-prod
spec:
  acme:
    server: https://acme-v02.api.letsencrypt.org/directory
    email: your-email@example.com
    privateKeySecretRef:
      name: letsencrypt-prod
    solvers:
    - http01:
        ingress:
          class: nginx
EOF
```

### 2. 네트워크 정책 설정
```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: trip-service-network-policy
  namespace: trip-service-prod
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: ingress-nginx
  egress:
  - to: []
    ports:
    - protocol: TCP
      port: 53
    - protocol: UDP
      port: 53
```

## 성능 최적화

### 1. 리소스 제한 설정
- CPU: 500m ~ 1000m
- Memory: 512Mi ~ 1Gi
- HPA 설정으로 자동 스케일링

### 2. 캐싱 전략
- Redis 클러스터 구성
- CDN 설정 (CloudFlare 등)

### 3. 데이터베이스 최적화
- 인덱스 설정
- 쿼리 최적화
- 연결 풀 설정
